{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load MVTec Dataset (train + test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_root = \"/kaggle/input/mvtec-ad/carpet\"\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# transformation (resize, normalize)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load TRAIN set (normal images only)\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root=\"/kaggle/input/mvtec-ad/carpet/train\",\n",
    "    transform=transform\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Load TEST set (normal + anomalous images)\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    root=\"/kaggle/input/mvtec-ad/carpet/test\",\n",
    "    transform=transform\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f\"Train images: {len(train_dataset)}, Test images: {len(test_dataset)}\")\n",
    "print(f\"Classes: {train_dataset.classes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Ground Truth Mask (MVTec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_ground_truth_mask(image_name, gt_dir):\n",
    "    mask_path = os.path.join(\n",
    "        \"/kaggle/input/mvtec-ad/carpet/ground_truth\",\n",
    "        image_name.replace(\".png\", \"_mask.png\")\n",
    "    )\n",
    "    return Image.open(mask_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fine-Tuning DDPM UNet on Normal Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from diffusers import DDPMScheduler, UNet2DModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# CONFIGURATION\n",
    "DATASET_ROOT = \"/kaggle/input/mvtec-ad/carpet/train\"\n",
    "OUTPUT_DIR = \"./fine_tuned_unet\"\n",
    "BATCH_SIZE = 2\n",
    "IMAGE_SIZE = 128\n",
    "EPOCHS = 30\n",
    "LR = 3e-5\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# DATASET\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "train_dataset = datasets.ImageFolder(root=DATASET_ROOT, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(f\"Loaded {len(train_dataset)} training images from {DATASET_ROOT}\")\n",
    "\n",
    "# LOAD PRETRAINED MODEL\n",
    "unet = UNet2DModel.from_pretrained(\n",
    "    \"google/ddpm-celebahq-256\", use_safetensors=False\n",
    ").to(DEVICE)\n",
    "\n",
    "unet.enable_gradient_checkpointing()\n",
    "\n",
    "# Freeze all params first\n",
    "for param in unet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze last UNet block + mid_block\n",
    "for name, param in unet.named_parameters():\n",
    "    if (\"up_blocks.2\" in name or \"up_blocks.3\" in name \n",
    "        or \"mid_block\" in name or \"down_blocks.3\" in name):\n",
    "        param.requires_grad = True\n",
    "\n",
    "print(\"Fine-tuning last UNet block + mid_block only.\")\n",
    "\n",
    "# SCHEDULER + OPTIMIZER\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, unet.parameters()), lr=LR)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Enable mixed precision\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# TRAINING LOOP\n",
    "unet.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for images, _ in loop:\n",
    "        images = images.to(DEVICE)\n",
    "        noise = torch.randn_like(images)\n",
    "        timesteps = torch.randint(\n",
    "            0, noise_scheduler.config.num_train_timesteps,\n",
    "            (images.shape[0],), device=DEVICE\n",
    "        )\n",
    "        noisy_images = noise_scheduler.add_noise(images, noise, timesteps)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():  \n",
    "            noise_pred = unet(noisy_images, timesteps).sample\n",
    "            loss = criterion(noise_pred, noise)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] | Avg Loss: {avg_loss:.6f}\")\n",
    "\n",
    "# SAVE MODEL\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "unet.save_pretrained(OUTPUT_DIR)\n",
    "print(f\"Fine-tuned UNet saved at {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load Stable Diffusion UNet & Select Layers to Fine-Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
    "unet = pipeline.unet\n",
    "\n",
    "for param in unet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, param in unet.named_parameters():\n",
    "    if \"up_blocks.3\" in name or \"mid_block\" in name:\n",
    "        param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Running Reverse Diffusion for Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from diffusers import DDPMScheduler, UNet2DModel\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# CONFIGURATION\n",
    "TEST_ROOT = \"/kaggle/input/mvtec-ad/carpet/test\"\n",
    "MODEL_PATH = \"./fine_tuned_unet\"\n",
    "OUTPUT_DIR = \"./reconstructions\"\n",
    "BATCH_SIZE = 2\n",
    "IMAGE_SIZE = 128\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# LOAD TEST DATA\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "test_dataset = datasets.ImageFolder(root=TEST_ROOT, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Loaded {len(test_dataset)} test images from {TEST_ROOT}\")\n",
    "\n",
    "# LOAD MODEL + SCHEDULER\n",
    "unet = UNet2DModel.from_pretrained(MODEL_PATH).to(DEVICE)\n",
    "unet.eval()\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
    "\n",
    "# REVERSE DIFFUSION FUNCTION\n",
    "@torch.no_grad()\n",
    "def reconstruct_images(images, steps=250):\n",
    "    noisy = images.clone()\n",
    "    timesteps = torch.linspace(\n",
    "        noise_scheduler.config.num_train_timesteps - 1, 0,\n",
    "        steps, dtype=torch.long, device=DEVICE\n",
    "    )\n",
    "    for t in timesteps:\n",
    "        model_output = unet(noisy, t).sample\n",
    "        noisy = noise_scheduler.step(model_output, t, noisy).prev_sample\n",
    "    return noisy\n",
    "\n",
    "# INFERENCE\n",
    "anomaly_scores = []\n",
    "for i, (images, labels) in enumerate(tqdm(test_loader, desc=\"Testing\")):\n",
    "    images = images.to(DEVICE)\n",
    "\n",
    "    # Reconstruct images\n",
    "    recon = reconstruct_images(images)\n",
    "\n",
    "    # Pixel-wise reconstruction error\n",
    "    pixel_error = ((images - recon) ** 2).mean(dim=[1, 2, 3])\n",
    "    anomaly_scores.extend(pixel_error.cpu().numpy())\n",
    "\n",
    "    # Save comparison image\n",
    "    if i == 0:\n",
    "        vutils.save_image(torch.cat([images, recon], dim=0),\n",
    "                          os.path.join(OUTPUT_DIR, \"comparison.png\"),\n",
    "                          nrow=BATCH_SIZE, normalize=True)\n",
    "\n",
    "# RESULTS\n",
    "anomaly_scores = np.array(anomaly_scores)\n",
    "print(f\"Computed anomaly scores for {len(anomaly_scores)} images.\")\n",
    "print(f\"Mean Score: {anomaly_scores.mean():.6f}, Max Score: {anomaly_scores.max():.6f}\")\n",
    "\n",
    "# SAVE CSV\n",
    "import pandas as pd\n",
    "pd.DataFrame({\"score\": anomaly_scores, \"label\": test_dataset.targets}).to_csv(\n",
    "    os.path.join(OUTPUT_DIR, \"anomaly_scores.csv\"), index=False\n",
    ")\n",
    "print(f\"Saved anomaly scores to {OUTPUT_DIR}/anomaly_scores.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1946896,
     "sourceId": 3209332,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
