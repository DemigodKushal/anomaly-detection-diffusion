{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:06:04.089070Z",
     "iopub.status.busy": "2025-11-25T17:06:04.088437Z",
     "iopub.status.idle": "2025-11-25T17:07:37.135755Z",
     "shell.execute_reply": "2025-11-25T17:07:37.134990Z",
     "shell.execute_reply.started": "2025-11-25T17:06:04.089044Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q diffusers==0.30.0 transformers accelerate safetensors opensimplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:07:37.137831Z",
     "iopub.status.busy": "2025-11-25T17:07:37.137594Z",
     "iopub.status.idle": "2025-11-25T17:07:46.691400Z",
     "shell.execute_reply": "2025-11-25T17:07:46.690815Z",
     "shell.execute_reply.started": "2025-11-25T17:07:37.137808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds_root = \"/kaggle/input/mvtec-ad/carpet\"\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Creating transformer and loading dataset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),                         \n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root=os.path.join(ds_root, \"train\"),\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    root=os.path.join(ds_root, \"test\"),\n",
    "    transform=transform\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:07:46.693091Z",
     "iopub.status.busy": "2025-11-25T17:07:46.692615Z",
     "iopub.status.idle": "2025-11-25T17:07:46.711757Z",
     "shell.execute_reply": "2025-11-25T17:07:46.711109Z",
     "shell.execute_reply.started": "2025-11-25T17:07:46.693066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#\n",
    "# Creating a basic UNet with sinusoidal time embeddings that help predict noise\n",
    "# credits: https://apxml.com/courses/advanced-diffusion-architectures/chapter-2-advanced-unet-architectures/unet-time-embeddings\n",
    "# pretty interesting and \n",
    "\n",
    "\n",
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim: int):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        t: [B] (int or float timesteps)\n",
    "        returns: [B, dim]\n",
    "        \"\"\"\n",
    "        device = t.device\n",
    "        half_dim = self.dim // 2\n",
    "        # [half_dim]\n",
    "        freqs = torch.exp(\n",
    "            torch.arange(half_dim, device=device) * (-math.log(10000.0) / (half_dim - 1))\n",
    "        )\n",
    "        # [B, 1] * [half_dim] -> [B, half_dim]\n",
    "        args = t.float().unsqueeze(1) * freqs.unsqueeze(0)\n",
    "        # [B, dim]\n",
    "        emb = torch.cat([torch.sin(args), torch.cos(args)], dim=1)\n",
    "        return emb\n",
    "\n",
    "\n",
    "# --------- Building blocks ---------\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"\n",
    "    (Conv -> Norm -> ReLU) x2 with optional time embedding.\n",
    "    in_ch -> out_ch\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch: int, out_ch: int, time_dim: int = None):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1)\n",
    "        self.norm1 = nn.BatchNorm2d(out_ch)\n",
    "        self.norm2 = nn.BatchNorm2d(out_ch)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.time_mlp = None\n",
    "        if time_dim is not None:\n",
    "            self.time_mlp = nn.Linear(time_dim, out_ch)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t_emb: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: [B, C, H, W]\n",
    "        t_emb: [B, time_dim] or None\n",
    "        \"\"\"\n",
    "        h = self.conv1(x)\n",
    "        h = self.norm1(h)\n",
    "\n",
    "        if self.time_mlp is not None and t_emb is not None:\n",
    "            # [B, out_ch]\n",
    "            time_bias = self.time_mlp(t_emb)\n",
    "            # [B, out_ch, 1, 1]\n",
    "            time_bias = time_bias.unsqueeze(-1).unsqueeze(-1)\n",
    "            h = h + time_bias\n",
    "\n",
    "        h = self.act(h)\n",
    "        h = self.conv2(h)\n",
    "        h = self.norm2(h)\n",
    "        h = self.act(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    DoubleConv + MaxPool\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch: int, out_ch: int, time_dim: int):\n",
    "        super().__init__()\n",
    "        self.conv = DoubleConv(in_ch, out_ch, time_dim)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t_emb: torch.Tensor):\n",
    "        x = self.conv(x, t_emb)   # [B, out_ch, H, W]\n",
    "        p = self.pool(x)         # [B, out_ch, H/2, W/2]\n",
    "        return x, p              # return features + pooled\n",
    "\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Up-conv (transpose) + concat skip + DoubleConv\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch: int, out_ch: int, time_dim: int):\n",
    "        \"\"\"\n",
    "        in_ch: channels coming into this block (from lower level),\n",
    "               this goes into ConvTranspose2d\n",
    "        out_ch: channels after up-conv; skip connection will also be out_ch,\n",
    "                so DoubleConv sees in_ch = out_ch * 2\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2)\n",
    "        # after up: [B, out_ch, H*2, W*2]\n",
    "        # skip:     [B, out_ch, H*2, W*2]\n",
    "        # concat:   [B, 2*out_ch, H*2, W*2]\n",
    "        self.conv = DoubleConv(out_ch * 2, out_ch, time_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, skip: torch.Tensor, t_emb: torch.Tensor):\n",
    "        x = self.up(x)\n",
    "        # handle possible mismatch due to odd sizes\n",
    "        if x.shape[-2:] != skip.shape[-2:]:\n",
    "            diff_y = skip.shape[-2] - x.shape[-2]\n",
    "            diff_x = skip.shape[-1] - x.shape[-1]\n",
    "            x = F.pad(x, [diff_x // 2, diff_x - diff_x // 2,\n",
    "                          diff_y // 2, diff_y - diff_y // 2])\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.conv(x, t_emb)\n",
    "        return x\n",
    "\n",
    "\n",
    "# --------- Full UNet ---------\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    UNet with time conditioning, suitable for DDPM-style noise prediction.\n",
    "\n",
    "    - in_channels: 4 for SD latents, or 3 for RGB pixels\n",
    "    - base_channels: base width of the network\n",
    "    - time_dim: dimension of time embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int = 4, base_channels: int = 64, time_dim: int = 256):\n",
    "        super().__init__()\n",
    "\n",
    "        # time embedding (sinusoidal + MLP)\n",
    "        self.time_embed = SinusoidalTimeEmbedding(time_dim)\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(time_dim, time_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(time_dim, time_dim),\n",
    "        )\n",
    "\n",
    "        # Channel sizes\n",
    "        c1 = base_channels          # 64\n",
    "        c2 = base_channels * 2      # 128\n",
    "        c3 = base_channels * 4      # 256\n",
    "        c4 = base_channels * 8      # 512\n",
    "        c5 = base_channels * 16     # 1024 (bottleneck)\n",
    "\n",
    "        # Down path: in -> 64 -> 128 -> 256 -> 512\n",
    "        self.down1 = DownBlock(in_channels, c1, time_dim)  # 4 -> 64\n",
    "        self.down2 = DownBlock(c1,          c2, time_dim)  # 64 -> 128\n",
    "        self.down3 = DownBlock(c2,          c3, time_dim)  # 128 -> 256\n",
    "        self.down4 = DownBlock(c3,          c4, time_dim)  # 256 -> 512\n",
    "\n",
    "        # Bottleneck: 512 -> 1024\n",
    "        self.bot = DoubleConv(c4, c5, time_dim)\n",
    "\n",
    "        # Up path: 1024 -> 512 -> 256 -> 128 -> 64\n",
    "        self.up1 = UpBlock(c5, c4, time_dim)   # in: 1024, out: 512\n",
    "        self.up2 = UpBlock(c4, c3, time_dim)   # in: 512,  out: 256\n",
    "        self.up3 = UpBlock(c3, c2, time_dim)   # in: 256,  out: 128\n",
    "        self.up4 = UpBlock(c2, c1, time_dim)   # in: 128,  out: 64\n",
    "\n",
    "        # Final 1x1 conv: 64 -> in_channels (4 for latents)\n",
    "        self.out_conv = nn.Conv2d(c1, in_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: [B, in_channels, H, W]   (noisy image or latent)\n",
    "        t: [B]                      (timestep indices)\n",
    "        returns: [B, in_channels, H, W]  (predicted noise)\n",
    "        \"\"\"\n",
    "        # embed t\n",
    "        t_emb = self.time_embed(t)          # [B, time_dim]\n",
    "        t_emb = self.time_mlp(t_emb)       # [B, time_dim]\n",
    "\n",
    "        # Down path\n",
    "        d1, p1 = self.down1(x,  t_emb)     # d1: [B, 64,  H,   W]\n",
    "        d2, p2 = self.down2(p1, t_emb)     # d2: [B, 128, H/2, W/2]\n",
    "        d3, p3 = self.down3(p2, t_emb)     # d3: [B, 256, H/4, W/4]\n",
    "        d4, p4 = self.down4(p3, t_emb)     # d4: [B, 512, H/8, W/8]\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bot(p4, t_emb)            # [B, 1024, H/8, W/8]\n",
    "\n",
    "        # Up path with skip connections\n",
    "        u1 = self.up1(b,  d4, t_emb)       # [B, 512, H/8, W/8]\n",
    "        u2 = self.up2(u1, d3, t_emb)       # [B, 256, H/4, W/4]\n",
    "        u3 = self.up3(u2, d2, t_emb)       # [B, 128, H/2, W/2]\n",
    "        u4 = self.up4(u3, d1, t_emb)       # [B, 64,  H,   W]\n",
    "\n",
    "        out = self.out_conv(u4)            # [B, in_channels, H, W]\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:07:46.713810Z",
     "iopub.status.busy": "2025-11-25T17:07:46.713602Z",
     "iopub.status.idle": "2025-11-25T17:07:46.738517Z",
     "shell.execute_reply": "2025-11-25T17:07:46.737947Z",
     "shell.execute_reply.started": "2025-11-25T17:07:46.713793Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from diffusers import AutoencoderKL\n",
    "# import torch\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# vae = AutoencoderKL.from_pretrained(\n",
    "#     \"runwayml/stable-diffusion-v1-5\",\n",
    "#     subfolder=\"vae\"\n",
    "# ).to(device)\n",
    "# vae.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:07:46.739328Z",
     "iopub.status.busy": "2025-11-25T17:07:46.739110Z",
     "iopub.status.idle": "2025-11-25T17:07:48.567935Z",
     "shell.execute_reply": "2025-11-25T17:07:48.567283Z",
     "shell.execute_reply.started": "2025-11-25T17:07:46.739310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from opensimplex import OpenSimplex\n",
    "\n",
    "# Took help of GPT and the the code of AnoDDPM paper for this implementation\n",
    "\n",
    "def simplex_noise(\n",
    "    batch,\n",
    "    ch,\n",
    "    H,\n",
    "    W,\n",
    "    seed=0,\n",
    "    persistence=0.5,\n",
    "    colorless=True,\n",
    "    normalize_per_sample=False,\n",
    "    device=\"cpu\",\n",
    "    dtype=torch.float32,\n",
    "):\n",
    "    \"\"\"\n",
    "    Simple, fast AnoDDPM-style simplex noise generator.\n",
    "    \n",
    "    Frequencies: ν = 2^-1 ... 2^-6  (fixed, as in AnoDDPM)\n",
    "    persistence: amplitude decay per octave\n",
    "    colorless: if True → same noise map for all channels\n",
    "    \"\"\"\n",
    "\n",
    "    # AnoDDPM fixed multi-scale frequencies\n",
    "    # freqs = [2**(-i) for i in range(1, 7)]   # 0.5, 0.25, ..., 1/64\n",
    "    freqs = [2**(-6)]\n",
    "\n",
    "    # Coordinates\n",
    "    xs = np.linspace(0.0, 1.0, W, endpoint=False).astype(np.float32)\n",
    "    ys = np.linspace(0.0, 1.0, H, endpoint=False).astype(np.float32)\n",
    "\n",
    "    def build_field(rng):\n",
    "        \"\"\"Produces a single H×W simplex noise map with AnoDDPM frequencies.\"\"\"\n",
    "        field = np.zeros((H, W), dtype=np.float32)\n",
    "        for o, freq in enumerate(freqs):\n",
    "            amp = persistence ** o\n",
    "            for i, yi in enumerate(ys):\n",
    "                for j, xj in enumerate(xs):\n",
    "                    field[i, j] += amp * float(rng.noise2(xj * freq, yi * freq))\n",
    "\n",
    "        # normalize\n",
    "        if normalize_per_sample:\n",
    "            field = (field - field.mean()) / (field.std() + 1e-9)\n",
    "        return field\n",
    "\n",
    "    rng = OpenSimplex(seed)\n",
    "\n",
    "    # -------- colorless mode (AnoDDPM default) --------\n",
    "    if colorless:\n",
    "        base = build_field(rng)\n",
    "        base = (base - base.mean()) / (base.std() + 1e-9)\n",
    "\n",
    "        arr = np.tile(base[None, None], (batch, ch, 1, 1)).astype(np.float32)\n",
    "\n",
    "    # -------- multi-channel independent noise --------\n",
    "    else:\n",
    "        arr = np.zeros((batch, ch, H, W), dtype=np.float32)\n",
    "        loc_seed = seed\n",
    "        for b in range(batch):\n",
    "            for c in range(ch):\n",
    "                rng_local = OpenSimplex(loc_seed)\n",
    "                f = build_field(rng_local)\n",
    "                f = (f - f.mean()) / (f.std() + 1e-9)\n",
    "                arr[b, c] = f\n",
    "                loc_seed += 1\n",
    "\n",
    "    return torch.tensor(arr, device=device, dtype=dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:07:48.568934Z",
     "iopub.status.busy": "2025-11-25T17:07:48.568694Z",
     "iopub.status.idle": "2025-11-25T17:08:32.817541Z",
     "shell.execute_reply": "2025-11-25T17:08:32.816746Z",
     "shell.execute_reply.started": "2025-11-25T17:07:48.568909Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loading VAE for working in the Latent Space of SD 1.5\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from diffusers import AutoencoderKL\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    subfolder=\"vae\"\n",
    ").to(device)\n",
    "vae.eval()\n",
    "vae.requires_grad_(False)\n",
    "\n",
    "batch_size = 8 \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:08:32.818971Z",
     "iopub.status.busy": "2025-11-25T17:08:32.818399Z",
     "iopub.status.idle": "2025-11-25T17:09:37.017634Z",
     "shell.execute_reply": "2025-11-25T17:09:37.016737Z",
     "shell.execute_reply.started": "2025-11-25T17:08:32.818951Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# precomputing latents for training because ran into kaggle oom issues\n",
    "\n",
    "all_latents = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x0,_ in train_loader:\n",
    "        x0 = x0.repeat(1,3,1,1) # grayscale input and vae expects 3 channels\n",
    "        x0 = x0.to(device) \n",
    "        x0_norm = x0 * 2 - 1   # [0,1] -> [-1,1]\n",
    "        # encode with VAE\n",
    "        posterior = vae.encode(x0_norm)\n",
    "        # use mean/sample for deterministic encoding\n",
    "        z0 = posterior.latent_dist.mean  # [B, 4, H_lat, W_lat]\n",
    "        # scale like SD\n",
    "        z0 = z0 * 0.18215\n",
    "        all_latents.append(z0.cpu())\n",
    "\n",
    "all_latents = torch.cat(all_latents, dim=0)  # [N, 4, H_lat, W_lat]\n",
    "print(\"Latents shape:\", all_latents.shape)\n",
    "torch.save(all_latents, \"train_latents.pt\")\n",
    "print(\"Saved latents to train_latents.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:09:37.019061Z",
     "iopub.status.busy": "2025-11-25T17:09:37.018800Z",
     "iopub.status.idle": "2025-11-25T17:09:37.032130Z",
     "shell.execute_reply": "2025-11-25T17:09:37.031500Z",
     "shell.execute_reply.started": "2025-11-25T17:09:37.019036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class LatentDataset(Dataset):\n",
    "    def __init__(self, latents_path: str):\n",
    "        super().__init__()\n",
    "        self.latents = torch.load(latents_path)  # [N, 4, H_lat, W_lat], float32\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.latents.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.latents[idx]  # [4, H_lat, W_lat]\n",
    "\n",
    "\n",
    "latent_dataset = LatentDataset(\"train_latents.pt\")\n",
    "latent_loader = DataLoader(latent_dataset, batch_size=16, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:12:27.276485Z",
     "iopub.status.busy": "2025-11-25T17:12:27.275811Z",
     "iopub.status.idle": "2025-11-25T17:12:27.600619Z",
     "shell.execute_reply": "2025-11-25T17:12:27.599963Z",
     "shell.execute_reply.started": "2025-11-25T17:12:27.276456Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# initialize model and optimizer\n",
    "in_channels = 4\n",
    "base_channels = 64\n",
    "time_dim = 256\n",
    "\n",
    "model = UNet(in_channels=in_channels, base_channels=base_channels, time_dim=time_dim).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:12:27.621118Z",
     "iopub.status.busy": "2025-11-25T17:12:27.620851Z",
     "iopub.status.idle": "2025-11-25T17:13:06.515346Z",
     "shell.execute_reply": "2025-11-25T17:13:06.514405Z",
     "shell.execute_reply.started": "2025-11-25T17:12:27.621099Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# training block\n",
    "T = 1000  #max number of noising steps\n",
    "\n",
    "# Scheduler start and end values\n",
    "beta_start = 1e-4\n",
    "beta_end   = 0.02\n",
    "\n",
    "# precomputing schedueler constants\n",
    "\n",
    "betas = torch.linspace(beta_start, beta_end, T, dtype=torch.float32)\n",
    "alphas = 1.0 - betas\n",
    "alpha_bars = torch.cumprod(alphas, dim=0)  # [T]\n",
    "\n",
    "sqrt_alpha_bars      = torch.sqrt(alpha_bars)\n",
    "sqrt_one_minus_abars = torch.sqrt(1.0 - alpha_bars)\n",
    "\n",
    "# move to gpu\n",
    "betas               = betas.to(device)\n",
    "alphas              = alphas.to(device)\n",
    "alpha_bars          = alpha_bars.to(device)\n",
    "sqrt_alpha_bars     = sqrt_alpha_bars.to(device)\n",
    "sqrt_one_minus_abars= sqrt_one_minus_abars.to(device)\n",
    "\n",
    "# get zt from z0,t and eps\n",
    "def q_sample(z0, t, eps):\n",
    "    B = z0.shape[0]\n",
    "    sqrt_ab    = sqrt_alpha_bars[t].view(B, 1, 1, 1)        # [B,1,1,1]\n",
    "    sqrt_ombab = sqrt_one_minus_abars[t].view(B, 1, 1, 1)   # [B,1,1,1]\n",
    "    return sqrt_ab * z0 + sqrt_ombab * eps\n",
    "\n",
    "# training loop\n",
    "num_epochs = 20  \n",
    "global_step = 0\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for z0 in latent_loader:\n",
    "        z0 = z0.to(device)  # [B, 4, H_lat, W_lat]\n",
    "        B  = z0.shape[0]\n",
    "\n",
    "        # sample random timesteps t for each sample in batch\n",
    "        t = torch.randint(low=T//4, high=T, size=(B,), device=device)\n",
    "\n",
    "        eps = simplex_noise(\n",
    "        batch=B,\n",
    "        ch=4,                 \n",
    "        H=64, W=64,         \n",
    "        seed=123,\n",
    "        persistence=0.5,\n",
    "        colorless=True,\n",
    "        device=\"cuda\",\n",
    "    )\n",
    "\n",
    "        eps = eps.to(device)\n",
    "\n",
    "        z_t = q_sample(z0, t, eps)\n",
    "\n",
    "        eps_hat = model(z_t, t)\n",
    "\n",
    "        loss = F.mse_loss(eps_hat, eps)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - loss: {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:13:49.187950Z",
     "iopub.status.busy": "2025-11-25T17:13:49.187627Z",
     "iopub.status.idle": "2025-11-25T17:13:49.199784Z",
     "shell.execute_reply": "2025-11-25T17:13:49.198865Z",
     "shell.execute_reply.started": "2025-11-25T17:13:49.187929Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model.eval()\n",
    "vae.eval()\n",
    "\n",
    "vae.requires_grad_(False)\n",
    "model.requires_grad_(False)\n",
    "\n",
    "def q_sample(z0, t, eps, sqrt_alpha_bars, sqrt_one_minus_abars):\n",
    "    B = z0.shape[0]\n",
    "    sqrt_ab    = sqrt_alpha_bars[t].view(B, 1, 1, 1)\n",
    "    sqrt_ombab = sqrt_one_minus_abars[t].view(B, 1, 1, 1)\n",
    "    return sqrt_ab * z0 + sqrt_ombab * eps, sqrt_ab, sqrt_ombab\n",
    "\n",
    "@torch.no_grad()\n",
    "def reconstruct_and_heatmap(x_batch, t_step):\n",
    "\n",
    "    B = x_batch.shape[0]\n",
    "    x0 = x_batch.to(device)\n",
    "\n",
    "    x0 = x0.repeat(1,3,1,1)\n",
    "    x0_norm = x0 * 2 - 1                     \n",
    "    posterior = vae.encode(x0_norm)\n",
    "    z0 = posterior.latent_dist.sample() * 0.18215 # SD standardize smtn\n",
    "\n",
    "    t = torch.full((B,), t_step, device=device, dtype=torch.long)\n",
    "\n",
    "    eps = simplex_noise(\n",
    "    batch=B,\n",
    "    ch=4,                 \n",
    "    H=64, W=64,         \n",
    "    seed=123,\n",
    "    persistence=0.5,\n",
    "    colorless=True,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "    eps = eps.to(device)\n",
    "\n",
    "    z_t, sqrt_ab, sqrt_ombab = q_sample(z0, t, eps, sqrt_alpha_bars, sqrt_one_minus_abars)\n",
    "\n",
    "    eps_hat = model(z_t, t)  # [B, 4, H_lat, W_lat]\n",
    "\n",
    "    z_recon = (z_t - sqrt_ombab * eps_hat) / sqrt_ab\n",
    "\n",
    "    z_recon_dec = z_recon / 0.18215\n",
    "    x_recon = vae.decode(z_recon_dec).sample  \n",
    "    x_recon = (x_recon + 1) / 2               \n",
    "    residual = (x_recon - x0) ** 2            \n",
    "    heat = residual.mean(dim=1)               \n",
    "\n",
    "    #heatmap for anomalies\n",
    "    \n",
    "    B, H, W = heat.shape\n",
    "    heat_flat = heat.view(B, -1)\n",
    "    h_min = heat_flat.min(dim=1, keepdim=True)[0]\n",
    "    h_max = heat_flat.max(dim=1, keepdim=True)[0]\n",
    "    heat_norm = (heat_flat - h_min) / (h_max - h_min + 1e-8)\n",
    "    heat_norm = heat_norm.view(B, H, W)\n",
    "\n",
    "    return x0.cpu(), x_recon.cpu(), heat_norm.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:13:49.754853Z",
     "iopub.status.busy": "2025-11-25T17:13:49.754159Z",
     "iopub.status.idle": "2025-11-25T17:13:55.393334Z",
     "shell.execute_reply": "2025-11-25T17:13:55.392261Z",
     "shell.execute_reply.started": "2025-11-25T17:13:49.754830Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True)\n",
    "t_step = 500  \n",
    "\n",
    "x_test_batch, _ = next(iter(test_loader))  \n",
    "x_orig, x_recon, heatmap = reconstruct_and_heatmap(x_test_batch, t_step)\n",
    "\n",
    "\n",
    "B = x_orig.shape[0]\n",
    "n_show = min(B, 4) \n",
    "\n",
    "plt.figure(figsize=(9, 3 * n_show))\n",
    "\n",
    "for i in range(n_show):\n",
    "    plt.subplot(n_show, 3, 3*i + 1)\n",
    "    plt.imshow(x_orig[i].permute(1, 2, 0).numpy())\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(n_show, 3, 3*i + 2)\n",
    "    plt.imshow(x_recon[i].permute(1, 2, 0).numpy())\n",
    "    plt.title(\"Reconstruction\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(n_show, 3, 3*i + 3)\n",
    "    img = x_orig[i].permute(1, 2, 0).numpy()\n",
    "    hm  = heatmap[i].numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(hm, cmap=\"jet\", alpha=0.5)  # overlay\n",
    "    plt.title(\"Anomaly heatmap\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1946896,
     "sourceId": 3209332,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
