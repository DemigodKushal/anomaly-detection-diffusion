{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a4ac2a",
   "metadata": {},
   "source": [
    "1. Imports & Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee3d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import clip\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c012fe2",
   "metadata": {},
   "source": [
    "2. MVTec Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54df68",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/kaggle/input/mvtec-ad\"\n",
    "\n",
    "def load_images(category=\"carpet\", img_type=\"train\", resize=256, limit=None):\n",
    "    path = os.path.join(DATASET_PATH, category, img_type)\n",
    "    images, labels = [], []\n",
    "    \n",
    "    for defect_type in sorted(os.listdir(path)):\n",
    "        defect_path = os.path.join(path, defect_type)\n",
    "        files = glob.glob(os.path.join(defect_path, \"*.png\"))\n",
    "        if limit:\n",
    "            files = files[:limit]\n",
    "        for f in files:\n",
    "            img = cv2.imread(f)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (resize, resize))\n",
    "            images.append(img)\n",
    "            labels.append(0 if defect_type == \"good\" else 1)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bc11c7",
   "metadata": {},
   "source": [
    "3. Load CLIP + Stable Diffusion img2img Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3542ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading CLIP...\")\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "print(\"Loading Stable Diffusion img2img pipeline...\")\n",
    "pipe_img2img = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    safety_checker=None,\n",
    "    feature_extractor=None,\n",
    ")\n",
    "\n",
    "pipe_img2img = pipe_img2img.to(device)\n",
    "\n",
    "try:\n",
    "    pipe_img2img.enable_attention_slicing()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "generator = torch.Generator(device=device).manual_seed(42) if device==\"cuda\" else torch.Generator().manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57522a39",
   "metadata": {},
   "source": [
    "4. Stable Diffusion Reconstruction Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c915f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_img2img(np_img,\n",
    "                        prompt,\n",
    "                        negative_prompt,\n",
    "                        strength=0.35,\n",
    "                        guidance_scale=7.5,\n",
    "                        num_inference_steps=30,\n",
    "                        target_size=512):\n",
    "\n",
    "    pil = Image.fromarray(np_img.astype(np.uint8)).convert(\"RGB\")\n",
    "    pil_resized = pil.resize((target_size, target_size), resample=Image.LANCZOS)\n",
    "\n",
    "    call_kwargs = dict(\n",
    "        prompt=prompt,\n",
    "        strength=strength,\n",
    "        negative_prompt=negative_prompt,\n",
    "        guidance_scale=guidance_scale,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        generator=generator,\n",
    "        output_type=\"pil\",\n",
    "    )\n",
    "\n",
    "    call_kwargs_with_image = {**call_kwargs, \"image\": pil_resized}\n",
    "    call_kwargs_with_init_image = {**call_kwargs, \"init_image\": pil_resized}\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        with torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "            try:\n",
    "                result = pipe_img2img(**call_kwargs_with_image)\n",
    "            except TypeError:\n",
    "                result = pipe_img2img(**call_kwargs_with_init_image)\n",
    "    else:\n",
    "        try:\n",
    "            result = pipe_img2img(**call_kwargs_with_image)\n",
    "        except TypeError:\n",
    "            result = pipe_img2img(**call_kwargs_with_init_image)\n",
    "\n",
    "    recon = np.array(result.images[0]).astype(np.float32) / 255.0\n",
    "    return recon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5018200",
   "metadata": {},
   "source": [
    "5. Anomaly Scoring Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b954289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_mse(img, recon):\n",
    "    return float(np.mean((img/255.0 - recon) ** 2))\n",
    "\n",
    "def pixel_ssim(img, recon):\n",
    "    return float(1.0 - ssim(img/255.0, recon, channel_axis=2))\n",
    "\n",
    "def clip_similarity_error(img, recon):\n",
    "    img_pil = Image.fromarray(img.astype(np.uint8))\n",
    "    recon_pil = Image.fromarray((np.clip(recon, 0, 1) * 255).astype(np.uint8))\n",
    "    with torch.no_grad():\n",
    "        img_feat = clip_model.encode_image(preprocess(img_pil).unsqueeze(0).to(device))\n",
    "        recon_feat = clip_model.encode_image(preprocess(recon_pil).unsqueeze(0).to(device))\n",
    "        sim = torch.cosine_similarity(img_feat, recon_feat).item()\n",
    "    return float(1.0 - sim)\n",
    "\n",
    "def hybrid_score(img, recon, alpha=0.8):\n",
    "    return alpha * pixel_mse(img, recon) + (1.0 - alpha) * clip_similarity_error(img, recon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c1d2f2",
   "metadata": {},
   "source": [
    "6. Evaluation Loop (AUROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87148541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_img2img(category=\"carpet\", resize=256, limit_train=200, limit_test=None,\n",
    "                          prompt_template=\"a defect-free {category}\",\n",
    "                          negative_prompt=None,\n",
    "                          strength=0.35, guidance_scale=7.5,\n",
    "                          num_inference_steps=30, alpha=0.90):\n",
    "\n",
    "    print(f\"Loading data for category {category}...\")\n",
    "    train_imgs, train_labels = load_images(category, \"train\", resize=resize, limit=limit_train)\n",
    "    test_imgs, test_labels = load_images(category, \"test\", resize=resize, limit=limit_test)\n",
    "\n",
    "    print(\"Train normals:\", int((train_labels == 0).sum()), \"Test samples:\", len(test_imgs))\n",
    "\n",
    "    scores, labels = [], []\n",
    "    prompt = prompt_template.format(category=category)\n",
    "\n",
    "    for i in tqdm(range(len(test_imgs)), desc=\"Eval img2img reconstructions\"):\n",
    "        img = test_imgs[i]\n",
    "\n",
    "        recon = reconstruct_img2img(\n",
    "            img, prompt=prompt, negative_prompt=negative_prompt,\n",
    "            strength=strength, guidance_scale=guidance_scale,\n",
    "            num_inference_steps=num_inference_steps, target_size=512\n",
    "        )\n",
    "\n",
    "        h, w = img.shape[:2]\n",
    "        recon_resized = cv2.resize((recon * 255).astype(np.uint8), (w, h)) / 255.0\n",
    "\n",
    "        s = hybrid_score(img, recon_resized, alpha=alpha)\n",
    "        scores.append(s)\n",
    "        labels.append(int(test_labels[i]))\n",
    "\n",
    "    auc = roc_auc_score(labels, scores)\n",
    "    print(f\"Hybrid AUROC for {category}: {auc:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"auc\": auc,\n",
    "        \"scores\": np.array(scores),\n",
    "        \"labels\": np.array(labels),\n",
    "        \"test_imgs\": test_imgs,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531bde74",
   "metadata": {},
   "source": [
    "7. Heatmap Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2d74e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_map(img, recon):\n",
    "    diff = np.abs(img/255.0 - recon)\n",
    "    heatmap = np.mean(diff, axis=2)\n",
    "    heatmap /= (heatmap.max() + 1e-8)\n",
    "    return heatmap\n",
    "\n",
    "def show_sample_result(img, recon, idx=0, save_path=None):\n",
    "    if recon.shape[:2] != img.shape[:2]:\n",
    "        h, w = img.shape[:2]\n",
    "        recon = cv2.resize((recon * 255).astype(np.uint8), (w, h)) / 255.0\n",
    "\n",
    "    heatmap = anomaly_map(img, recon)\n",
    "\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,3,1); plt.imshow(img.astype(np.uint8)); plt.title(\"Original\"); plt.axis('off')\n",
    "    plt.subplot(1,3,2); plt.imshow((np.clip(recon,0,1)*255).astype(np.uint8)); plt.title(\"Reconstruction\"); plt.axis('off')\n",
    "    plt.subplot(1,3,3); plt.imshow(img.astype(np.uint8)); plt.imshow(heatmap, cmap='jet', alpha=0.5)\n",
    "    plt.title(\"Anomaly Map\"); plt.axis('off')\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a15ef95",
   "metadata": {},
   "source": [
    "8. Optuna Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d76b542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    strength = trial.suggest_float(\"strength\", 0.1, 0.7)\n",
    "    guidance_scale = trial.suggest_float(\"guidance_scale\", 2.0, 10.0)\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.5, 0.95)\n",
    "\n",
    "    auc_dict = evaluate_with_img2img(\n",
    "        category=\"carpet\",\n",
    "        strength=strength,\n",
    "        guidance_scale=guidance_scale,\n",
    "        alpha=alpha,\n",
    "        limit_train=50,\n",
    "        limit_test=50,\n",
    "    )\n",
    "\n",
    "    return auc_dict[\"auc\"]\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=64, show_progress_bar=True)\n",
    "\n",
    "print(\"Best AUROC:\", study.best_value)\n",
    "print(\"Best parameters:\", study.best_params)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
